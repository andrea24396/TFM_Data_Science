{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datat1_path = 'TFM/TFM_data/Training_t1/'\n",
    "datat1ce_path = 'TFM/TFM_data/Training_t1ce/'\n",
    "datat2_path = 'TFM/TFM_data/Training_t2/'\n",
    "dataflair_path = 'TFM/TFM_data/Training_flair/'\n",
    "seg_path = 'TFM/TFM_data/Training_seg/' # Carpeta con los 162 archivos _seg.nii.gz\n",
    "\n",
    "imgst1_names = []\n",
    "imgst1ce_names = []\n",
    "imgst2_names = []\n",
    "imgsflair_names = []\n",
    "    \n",
    "for base, dirs, files in os.walk(datat1_path):\n",
    "    imgst1_names = files\n",
    "imgst1_names.sort()\n",
    "    \n",
    "for base, dirs, files in os.walk(datat1ce_path):\n",
    "    imgst1ce_names = files\n",
    "imgst1ce_names.sort()\n",
    "    \n",
    "for base, dirs, files in os.walk(datat2_path):\n",
    "    imgst2_names = files\n",
    "imgst2_names.sort()\n",
    "    \n",
    "for base, dirs, files in os.walk(dataflair_path):\n",
    "    imgsflair_names = files\n",
    "imgsflair_names.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brats18_2013_13_1_'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgst1_names[3][:-9] # toma hasta los ultimos 11 elementos que es donde aparece el tipo de archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modificamos el nombre para que tengan la ruta para poder cargarlos con nib.load \n",
    "tags_names = imgst1_names.copy()\n",
    "\n",
    "for i in range(len(imgst1_names)):\n",
    "    imgst1_names[i] = datat1_path + imgst1_names[i]\n",
    "    imgst1ce_names[i] = datat1ce_path + imgst1ce_names[i]\n",
    "    imgst2_names[i] = datat2_path + imgst2_names[i]\n",
    "    imgsflair_names[i] = dataflair_path + imgsflair_names[i]\n",
    "    tags_names[i] = seg_path + tags_names[i][:-9] + 'seg.nii.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos las listas vacías donde se almacenarán las imágenes\n",
    "data_t1 = []\n",
    "imagenes_t1 = []\n",
    "\n",
    "data_t1ce = []\n",
    "imagenes_t1ce = []\n",
    "\n",
    "data_t2 = []\n",
    "imagenes_t2 = []\n",
    "\n",
    "data_flair = []\n",
    "imagenes_flair = []\n",
    "\n",
    "for i in range(len(imgst1_names)):\n",
    "    data_t1.append(nib.load(imgst1_names[i]))\n",
    "    imagenes_t1.append(data_t1[i].get_data())\n",
    "    \n",
    "    data_t1ce.append(nib.load(imgst1ce_names[i]))\n",
    "    imagenes_t1ce.append(data_t1ce[i].get_data())\n",
    "    \n",
    "    data_t2.append(nib.load(imgst2_names[i]))\n",
    "    imagenes_t2.append(data_t2[i].get_data())\n",
    "    \n",
    "    data_flair.append(nib.load(imgsflair_names[i]))\n",
    "    imagenes_flair.append(data_flair[i].get_data())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos lo mismo pero para las etiquetas\n",
    "data_seg = []\n",
    "etiquetas = []\n",
    "\n",
    "for i in range(len(tags_names)):\n",
    "    data_seg.append(nib.load(tags_names[i]))\n",
    "    etiquetas.append(data_seg[i].get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagenes_t2) # número de pacientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 155)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenes_t2[1].shape # dimensión de datos por paciente (cada cerebro dividido en 240 rebanadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de una imagen axial de RM:  (240, 240)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension de una imagen axial de RM: \",imagenes_t2[1][:,:,4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducir el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que si entrenamos la red con la totalidad de las imágenes se demoraría mucho, los dos procedimientos seguidos para acortar el dataset son los siguientes:\n",
    "\n",
    "- **Eliminar imágenes del dataset de TCIA.** Esto se debe a que la calidad de las imágenes es bastante baja en comparación con la de otras imágenes de los otros datsets. Este conjunto de datos lo componen los últimos 54 pacientes, por lo que habrá un total de 12960 imágenes procedentes de este dataset.\n",
    "\n",
    "- **Eliminar las imágenes del principio y final del escáner de RM del paciente.** Estas primeras y últimas imágenes serán completamente negras, por lo que no aportarán ningún tipo de información a nuestro entrenamiento, y lo único que harían sería demorarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_t1 = np.asarray(imagenes_t1)\n",
    "imagenes_t1ce = np.asarray(imagenes_t1ce)\n",
    "imagenes_t2 = np.asarray(imagenes_t2)\n",
    "imagenes_flair = np.asarray(imagenes_flair)\n",
    "etiquetas = np.asarray(etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos con todas los pacientes, menos los 56 últimas. \n",
    "# Es decir, tomamos los 108 primeros pacientes de nuestro conjunto\n",
    "\n",
    "imagenes_t1 = imagenes_t1[0:108]\n",
    "imagenes_t1ce = imagenes_t1ce[0:108]\n",
    "imagenes_t2 = imagenes_t2[0:108]\n",
    "imagenes_flair = imagenes_flair[0:108]\n",
    "etiquetas = etiquetas[0:108]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División Train y Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t1 = imagenes_t1[:81]\n",
    "train_t1ce = imagenes_t1ce[:81]\n",
    "train_t2 = imagenes_t2[:81]\n",
    "train_flair = imagenes_flair[:81]\n",
    "train_seg = etiquetas[:81]\n",
    "\n",
    "test_t1 = imagenes_t1[81:]\n",
    "test_t1ce = imagenes_t1ce[81:]\n",
    "test_t2 = imagenes_t2[81:]\n",
    "test_flair = imagenes_flair[81:]\n",
    "test_seg = etiquetas[81:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', train_t1ce.shape)\n",
    "print('Test:', test_t1ce.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para hacer el conjunto global con todas las secuencias, tomaremos menos pacientes de cada tipo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.concatenate((train_t1[:40], train_t1ce[:40], train_t2[:40], train_flair[:40]))\n",
    "test_imgs = np.concatenate((test_t1[:15], test_t1ce[:15], test_t2[:15], test_flair[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_seg = np.repeat(train_seg[:40],4,axis=0)\n",
    "test_imgs_seg = np.repeat(test_seg[:15],4,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', train_imgs.shape)\n",
    "print('Test:', test_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminamos la agrupación de imágenes y etiquetas por paciente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso se realiza en tres pasos por separado, ya que al hacerlo en un solo paso tardaba mucho en ejecutar.\n",
    "Los tres arrays resultantes se concatenarán al final en uno solo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invertimos el orden de los ejes para poder eliminar la agrupación por pacientes\n",
    "train_t1 = np.transpose(train_t1, (0,3,2,1))\n",
    "test_t1 = np.transpose(test_t1, (0,3,2,1))\n",
    "\n",
    "train_t1ce = np.transpose(train_t1ce, (0,3,2,1))\n",
    "test_t1ce = np.transpose(test_t1ce, (0,3,2,1))\n",
    "\n",
    "train_t2 = np.transpose(train_t2, (0,3,2,1))\n",
    "test_t2 = np.transpose(test_t2, (0,3,2,1))\n",
    "\n",
    "train_flair = np.transpose(train_flair, (0,3,2,1))\n",
    "test_flair = np.transpose(test_flair, (0,3,2,1))\n",
    "\n",
    "train_seg = np.transpose(train_seg, (0,3,2,1))\n",
    "test_seg = np.transpose(test_seg, (0,3,2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_imgs = np.transpose(train_imgs, (0,3,2,1))\n",
    "test_imgs = np.transpose(test_imgs, (0,3,2,1))\n",
    "\n",
    "train_imgs_seg = np.transpose(train_imgs_seg, (0,3,2,1))\n",
    "test_imgs_seg = np.transpose(test_imgs_seg, (0,3,2,1))\n",
    "\n",
    "print('Train global:',train_imgs.shape)\n",
    "print('Test global:',test_imgs.shape)\n",
    "print('Train global_seg:',train_imgs_seg.shape)\n",
    "print('Test global_seg:',test_imgs_seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupamos los dos primeros índices\n",
    "train_t1 = np.reshape(a=train_t1, newshape=(12555,240,240))\n",
    "train_t1ce = np.reshape(a=train_t1ce, newshape=(12555,240,240))\n",
    "train_t2 = np.reshape(a=train_t2, newshape=(12555,240,240))\n",
    "train_flair = np.reshape(a=train_flair, newshape=(12555,240,240))\n",
    "train_seg = np.reshape(a=train_seg, newshape=(12555,240,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t1 = np.reshape(a=test_t1, newshape=(4185,240,240))\n",
    "test_t1ce = np.reshape(a=test_t1ce, newshape=(4185,240,240))\n",
    "test_t2 = np.reshape(a=test_t2, newshape=(4185,240,240))\n",
    "test_flair = np.reshape(a=test_flair, newshape=(4185,240,240))\n",
    "test_seg = np.reshape(a=test_seg, newshape=(4185,240,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.reshape(a=train_imgs, newshape=(24800,240,240))\n",
    "train_imgs_seg = np.reshape(a=train_imgs_seg, newshape=(24800,240,240))\n",
    "test_imgs = np.reshape(a=test_imgs, newshape=(9300,240,240))\n",
    "test_imgs_seg = np.reshape(a=test_imgs_seg, newshape=(9300,240,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./TFM/datasets/train_imgs.npy',train_imgs)\n",
    "np.save('./TFM/datasets/train_imgs_seg.npy',train_imgs_seg)\n",
    "np.save('./TFM/datasets/test_imgs.npy',test_imgs)\n",
    "np.save('./TFM/datasets/test_imgs_seg.npy',test_imgs_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./TFM/datasets/train_t1.npy',train_t1)\n",
    "np.save('./TFM/datasets/train_t1ce.npy',train_t1ce)\n",
    "np.save('./TFM/datasets/train_t2.npy',train_t2)\n",
    "np.save('./TFM/datasets/train_flair.npy',train_flair)\n",
    "np.save('./TFM/datasets/train_seg.npy',train_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./TFM/datasets/test_t1.npy',test_t1)\n",
    "np.save('./TFM/datasets/test_t1ce.npy',test_t1ce)\n",
    "np.save('./TFM/datasets/test_t2.npy',test_t2)\n",
    "np.save('./TFM/datasets/test_flair.npy',test_flair)\n",
    "np.save('./TFM/datasets/test_seg.npy',test_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si se empieza el notebook a partir de este punto, cargamos los datos de train/test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_t1 = np.load('./TFM/datasets/train_t1.npy')\n",
    "# train_t1ce = np.load('./TFM/datasets/train_t1ce.npy')\n",
    "# # train_t2 = np.load('./TFM/datasets/train_t2.npy')\n",
    "# # train_flair = np.load('./TFM/datasets/train_flair.npy')\n",
    "# train_seg = np.load('./TFM/datasets/train_seg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_t1 = np.load('./TFM/datasets/test_t1.npy')\n",
    "# test_t1ce = np.load('./TFM/datasets/test_t1ce.npy')\n",
    "# # test_t2 = np.load('./TFM/datasets/test_t2.npy')\n",
    "# # test_flair = np.load('./TFM/datasets/test_flair.npy')\n",
    "# test_seg = np.load('./TFM/datasets/test_seg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs = np.load('./TFM/datasets/train_imgs.npy')\n",
    "# train_imgs_seg = np.load('./TFM/datasets/train_imgs_seg.npy')\n",
    "# test_imgs = np.load('./TFM/datasets/test_imgs.npy')\n",
    "# test_imgs_seg = np.load('./TFM/datasets/test_imgs_seg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2, 1)\n",
    "plt.imshow(train_imgs[76], cmap='gray')\n",
    "plt.title('Imagen')\n",
    "\n",
    "plt.subplot(1,2, 2)\n",
    "plt.imshow(train_imgs_seg[76], cmap='gray')\n",
    "plt.title('Etiqueta')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una función que normalice las imágenes. Para ello, buscará el valor máximo de cada imagen, y la dividirá toda ella por este valor. De este modo, el mapa de píxeles que compondrá la imagen tendrá un rango de 0 a 1.\n",
    "\n",
    "Asímismo, esta función no hará ninguna acción sobre las imágenes que sean totalmente negras, es decir, las que se componen exclusivamente por 0s. Estas las dejará intactas, puesto que si las dividiera por su máximo (en este caso, 0), serían matrices compuestas por nan. De este modo, las imágenes seguirán siendo mapas de 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(imagenes):\n",
    "    \"\"\"Normaliza las imágenes contenidas en el array que se pasa como parámetro,\n",
    "    dividiéndo el valor de todos sus píxeles por el máximo.\n",
    "    No hace nada si la imagen es totalmente negra, i.e. suma = 0.\n",
    "    De este modo el mapa de píxeles tendrá valores entre 0 y 1\"\"\"\n",
    "    imgs = imagenes.copy()\n",
    "    \n",
    "    imgs_norm = [imgs[i]/np.max(imgs[i]) if np.sum(imgs[i])!=0 else imgs[i] for i in range(len(imgs)) ]  \n",
    "    imgs_norm = np.asarray(imgs_norm)\n",
    "        \n",
    "    return imgs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos ahora las imágenes\n",
    "train_t1_norm = normalizar(train_t1)\n",
    "train_t1ce_norm = normalizar(train_t1ce)\n",
    "train_imgs_norm = normalizar(train_imgs)\n",
    "\n",
    "test_t1_norm = normalizar(test_t1)\n",
    "test_t1ce_norm = normalizar(test_t1ce)\n",
    "test_imgs_norm = normalizar(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_imgs_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Comprobamos que efectivamente se han normalizado las imágenes, \n",
    "# tomando un elemento cualquiera de nuestro array inicial, y el mismo\n",
    "# del nuevo array, para ver si los píxeles tienen valores entre 0 y 1\n",
    "\n",
    "print('Antes de normalizar:')\n",
    "print(train_t1[65][120])\n",
    "print('')\n",
    "print('Después de normalizar:')\n",
    "print(train_t1_norm[65][120])\n",
    "\n",
    "# Comprobamos también que las imágenes inciales, compuestas solo por 0s, siguen igual y no aparecen como nan\n",
    "print('')\n",
    "print('Imagen negra después de normalizar:')\n",
    "print(train_t1_norm[1][120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar imágenes negras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las primeras y últimas imágenes de cada escáner de RM son totalmente negras, por lo que no aportan ninguna información útil a nuestra red. Es por esto que las eliminaremos para reducir las dimensiones de nuestro dataset y que el entrenamiento de la red neuronal no se demore demasiado.\n",
    "\n",
    "También es conveniente eliminar aquellas imágenes que son prácticamente negras en su totalidad y tampoco aportan mucha info para el entrenamiento. Estas imágenes tienen píxeles distintos de 0, pero estableceremos un umbral (suma de los píxeles de la imagen) mínimo a partir del cual consideraremos que la imagen aporta información relevante a nuestra red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_no_relevantes(imagenes, etiquetas, umbral): \n",
    "    \"\"\"Del array de imágenes de rebanadas de cerebro que se pasa, guarda el índice de aquellas \n",
    "    cuya suma sea inferior a un umbral, ya que serán imágenes casi completamente negras que no aporten mucha información. \n",
    "    Se obtienen los índices de las imágenes que nos interesan y se hace slicing del array original con estos índices.\n",
    "    Hace lo mismo con las etiquetas correspondientes.\"\"\"\n",
    "    \n",
    "    # posiciones de las imágenes casi enteras negras\n",
    "    indices_negras = [i for i,img in enumerate(imagenes) if np.sum(imagenes[i]) < umbral]\n",
    "    indices_negras = np.asarray(indices_negras) # convertimos la lista a array\n",
    "    \n",
    "    indices_todas = np.arange(len(imagenes))\n",
    "    \n",
    "    # posiciones de las imágenes con las que nos queremos quedar\n",
    "    ind_buenas = np.setdiff1d(indices_todas, indices_negras)\n",
    "    \n",
    "    imagenes2 = imagenes[ind_buenas]\n",
    "    etiquetas2 = etiquetas[ind_buenas]\n",
    "    \n",
    "    return imagenes2, etiquetas2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mostrar algunas imágenes con sus etiquetas correspondientes. Además, buscaremos una imagen que consideremos que no aporta la suficiente información relevante para nuestra red y obtendremos la suma de sus píxeles. \n",
    "\n",
    "Este valor nos servirá como umbral de referencia para eliminar otras imágenes poco relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "\n",
    "\n",
    "plt.subplot(3,3, 1)\n",
    "plt.imshow(train_t1_norm[120],cmap='gray')\n",
    "plt.title('Suma T1 = {}'.format(round(np.sum(train_t1_norm[120]),3)))\n",
    "\n",
    "plt.subplot(3,3, 2)\n",
    "plt.imshow(train_t1_norm[130],cmap='gray')\n",
    "plt.title('Suma T1 = {}'.format(round(np.sum(train_t1_norm[130]),3)))\n",
    "\n",
    "plt.subplot(3,3, 3)\n",
    "plt.imshow(train_t1_norm[140],cmap='gray')\n",
    "plt.title('Suma T1 = {}'.format(round(np.sum(train_t1_norm[140]),3)))\n",
    "\n",
    "\n",
    "plt.subplot(3,3, 4)\n",
    "plt.imshow(train_t1ce_norm[120],cmap='gray')\n",
    "plt.title('Suma T1ce = {}'.format(round(np.sum(train_t1ce_norm[120]),3)))\n",
    "\n",
    "plt.subplot(3,3, 5)\n",
    "plt.imshow(train_t1ce_norm[130],cmap='gray')\n",
    "plt.title('Suma T1ce = {}'.format(round(np.sum(train_t1ce_norm[130]),3)))\n",
    "\n",
    "plt.subplot(3,3, 6)\n",
    "plt.imshow(train_t1ce_norm[140],cmap='gray')\n",
    "plt.title('Suma T1ce = {}'.format(round(np.sum(train_t1ce_norm[140]),3)))\n",
    "\n",
    "\n",
    "plt.subplot(3,3, 7)\n",
    "plt.imshow(train_imgs_norm[10010],cmap='gray')\n",
    "plt.title('Suma global = {}'.format(round(np.sum(train_imgs_norm[10010]),3)))\n",
    "\n",
    "plt.subplot(3,3, 8)\n",
    "plt.imshow(train_imgs_norm[10020],cmap='gray')\n",
    "plt.title('Suma global = {}'.format(round(np.sum(train_imgs_norm[10020]),3)))\n",
    "\n",
    "plt.subplot(3,3, 9)\n",
    "plt.imshow(train_imgs_norm[10030],cmap='gray')\n",
    "plt.title('Suma global = {}'.format(round(np.sum(train_imgs_norm[10030]),3)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2, 1)\n",
    "plt.imshow(train_imgs_norm[10030],cmap='gray')\n",
    "plt.title('Suma global = {}'.format(round(np.sum(train_imgs_norm[10030]),3)))\n",
    "\n",
    "plt.subplot(2,2, 1)\n",
    "plt.imshow(train_imgs_norm[10030],cmap='gray')\n",
    "plt.title('Suma global = {}'.format(round(np.sum(train_imgs_norm[10030]),3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Este paso es muy importante realizarlo después de haber normalizado las imágenes, para que el umbral sirva por igual a todas.**\n",
    "\n",
    "Los umbrales escogidos son: \n",
    "- T1: 4500\n",
    "- T1 con contraste: 3500\n",
    "- conjunto con todas las secuencias: 5000\n",
    "\n",
    "En el último caso, el umbral escogido es mayor para tomar menos imágenes periféricas por paciente, y quedarse solo con las más centrales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antes de eliminar las imágenes poco relevantes, nuestro dataset de train tenía:')\n",
    "print(len(train_t1_norm), 'imágenes T1 y sus correspondiente etiquetas')\n",
    "print(len(train_t1ce_norm), 'imágenes T1 con contraste y sus correspondiente etiquetas')\n",
    "print(len(train_imgs_norm), 'imágenes de todas las secuencias y sus correspondiente etiquetas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train_t1,tags_train_t1 = eliminar_no_relevantes(imagenes=train_t1_norm, etiquetas=train_seg, umbral=4500)\n",
    "imgs_train_t1ce,tags_train_t1ce = eliminar_no_relevantes(imagenes=train_t1ce_norm, etiquetas=train_seg, umbral=3500)\n",
    "imgs_train_global, tags_train_global = eliminar_no_relevantes(imagenes=train_imgs_norm, etiquetas=train_imgs_seg, umbral=5000)\n",
    "\n",
    "imgs_test_t1,tags_test_t1 = eliminar_no_relevantes(imagenes=test_t1_norm, etiquetas=test_seg, umbral=4500)\n",
    "imgs_test_t1ce,tags_test_t1ce = eliminar_no_relevantes(imagenes=test_t1ce_norm, etiquetas=test_seg, umbral=3500)\n",
    "imgs_test_global, tags_test_global = eliminar_no_relevantes(imagenes=test_imgs_norm, etiquetas=test_imgs_seg, umbral=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Después de eliminar las imágenes poco relevantes, nuestro dataset de train tiene:')\n",
    "print(len(imgs_train_t1), 'imágenes T1 y sus correspondiente etiquetas')\n",
    "print(len(imgs_train_t1ce), 'imágenes T1 con contraste y sus correspondiente etiquetas')\n",
    "print(len(imgs_train_global), 'imágenes de todas las secuencias y sus correspondiente etiquetas')\n",
    "\n",
    "print('')\n",
    "print('Después de eliminar las imágenes poco relevantes, nuestro dataset de test tiene:')\n",
    "print(len(imgs_test_t1), 'imágenes T1 y sus correspondiente etiquetas')\n",
    "print(len(imgs_test_t1ce), 'imágenes T1 con contraste y sus correspondiente etiquetas')\n",
    "print(len(imgs_test_global), 'imágenes de todas las secuencias y sus correspondiente etiquetas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Binarizar etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas proporcionada por la organización de BraTS 2018 muestran la segmentación del glioma en el cerebro, diferenciando varias partes.\n",
    "\n",
    "Para hacerlo más sencillo, se ha decidido convertir estas etiquetas en binarias, de modo que las imágenes segmentadas sean mapas de 0s y 1s. De este modo, simplemente se identificaría la posición del tumor, sin hacer ninguna distinción de sus partes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN PARA HACER ETIQUETAS BINARIAS\n",
    "# En agradecimientos, incluir a Stack overflow, por salvarnos la vida con las dudas de código\n",
    "\n",
    "def binarizar_etiqueta(etiquetas):\n",
    "    \"\"\"Función a la que se le pasa un array de imágenes segmentadas. \n",
    "    Hace una copia para que no modificar el array original.\n",
    "    Convierte el mapa de píxeles en binario, haciendo 1 cualquier píxel con valor distinto de 0.\"\"\"\n",
    "    \n",
    "    tags = etiquetas.copy()\n",
    "    for tag in tags:\n",
    "        tag[tag > 0] = 1\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train_t1bin = binarizar_etiqueta(tags_train_t1)\n",
    "tags_train_t1cebin = binarizar_etiqueta(tags_train_t1ce)\n",
    "tags_train_globalbin = binarizar_etiqueta(tags_train_global)\n",
    "\n",
    "tags_test_t1bin = binarizar_etiqueta(tags_test_t1)\n",
    "tags_test_t1cebin = binarizar_etiqueta(tags_test_t1ce)\n",
    "tags_test_globalbin = binarizar_etiqueta(tags_test_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Antes de binarizar:')\n",
    "print(tags_train_t1[20][120])\n",
    "print('')\n",
    "print('Después de binarizar:')\n",
    "print(tags_train_t1bin[20][120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que las etiquetas se han hecho binarias. Vamos a mostrar un ejemplo de imagen de cerebro con sus etiquetas correspondientes, la original y la binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 9))\n",
    "\n",
    "\n",
    "plt.subplot(1,3, 1)\n",
    "plt.imshow(imgs_test_global[300],cmap='gray')\n",
    "plt.title('Image')\n",
    "\n",
    "plt.subplot(1,3, 2)\n",
    "plt.imshow(tags_test_global[300],cmap='gray')\n",
    "plt.title('Tag')\n",
    "\n",
    "plt.subplot(1,3, 3)\n",
    "plt.imshow(tags_test_globalbin[300],cmap='gray')\n",
    "plt.title('Binary tag')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación en train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar nuestra red, haremos una partición de train/test del 75/25 %.\n",
    "Tomaremos imágenes aleatoriamente del dataset global, junto con su etiqueta correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_train_t1 = list(range(len(imgs_train_t1)))\n",
    "# indices_train_t1ce = list(range(len(imgs_train_t1ce)))\n",
    "# indices_train_global = list(range(len(imgs_train_global)))\n",
    "\n",
    "# indices_test_t1 = list(range(len(imgs_test_t1)))\n",
    "# indices_test_t1ce = list(range(len(imgs_test_t1ce)))\n",
    "# indices_test_global = list(range(len(imgs_test_global)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(indices_train_t1)\n",
    "# random.shuffle(indices_train_t1ce)\n",
    "# random.shuffle(indices_train_global)\n",
    "\n",
    "# random.shuffle(indices_test_t1)\n",
    "# random.shuffle(indices_test_t1ce)\n",
    "# random.shuffle(indices_test_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_train_t1 = imgs_train_t1[indices_train_t1]\n",
    "# tags_train_t1 = tags_train_t1[indices_train_t1]\n",
    "# tags_train_t1bin = tags_train_t1bin[indices_train_t1]\n",
    "\n",
    "# imgs_train_t1ce = imgs_train_t1ce[indices_train_t1ce]\n",
    "# tags_train_t1ce = tags_train_t1ce[indices_train_t1ce]\n",
    "# tags_train_t1cebin = tags_train_t1cebin[indices_train_t1ce]\n",
    "\n",
    "# imgs_train_global = imgs_train_global[indices_train_global]\n",
    "# tags_train_global = tags_train_global[indices_train_global]\n",
    "# tags_train_globalbin = tags_train_globalbin[indices_train_global]\n",
    "\n",
    "\n",
    "# imgs_test_t1 = imgs_test_t1[indices_test_t1]\n",
    "# tags_test_t1 = tags_test_t1[indices_test_t1]\n",
    "# tags_test_t1bin = tags_test_t1bin[indices_test_t1]\n",
    "\n",
    "# imgs_test_t1ce = imgs_test_t1ce[indices_test_t1ce]\n",
    "# tags_test_t1ce = tags_test_t1ce[indices_test_t1ce]\n",
    "# tags_test_t1cebin = tags_test_t1cebin[indices_test_t1ce]\n",
    "\n",
    "# imgs_test_global = imgs_test_global[indices_test_global]\n",
    "# tags_test_global = tags_test_global[indices_test_global]\n",
    "# tags_test_globalbin = tags_test_globalbin[indices_test_global]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a guardar los arrays obtenidos, de modo que se puedan cargar en futuras ocasiones sin tener que ejecutar todo el código de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./TFM/datasets/train_test/imgs_train_t1.npy',imgs_train_t1)\n",
    "np.save('./TFM/datasets/train_test/tags_train_t1.npy',tags_train_t1)\n",
    "np.save('./TFM/datasets/train_test/tags_train_t1bin.npy',tags_train_t1bin)\n",
    "\n",
    "np.save('./TFM/datasets/train_test/imgs_train_t1ce.npy',imgs_train_t1ce)\n",
    "np.save('./TFM/datasets/train_test/tags_train_t1ce.npy',tags_train_t1ce)\n",
    "np.save('./TFM/datasets/train_test/tags_train_t1cebin.npy',tags_train_t1cebin)\n",
    "\n",
    "np.save('./TFM/datasets/train_test/imgs_train_global.npy',imgs_train_global)\n",
    "np.save('./TFM/datasets/train_test/tags_train_global.npy',tags_train_global)\n",
    "np.save('./TFM/datasets/train_test/tags_train_globalbin.npy',tags_train_globalbin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./TFM/datasets/train_test/imgs_test_t1.npy',imgs_test_t1)\n",
    "np.save('./TFM/datasets/train_test/tags_test_t1.npy',tags_test_t1)\n",
    "np.save('./TFM/datasets/train_test/tags_test_t1bin.npy',tags_test_t1bin)\n",
    "\n",
    "np.save('./TFM/datasets/train_test/imgs_test_t1ce.npy',imgs_test_t1ce)\n",
    "np.save('./TFM/datasets/train_test/tags_test_t1ce.npy',tags_test_t1ce)\n",
    "np.save('./TFM/datasets/train_test/tags_test_t1cebin.npy',tags_test_t1cebin)\n",
    "\n",
    "np.save('./TFM/datasets/train_test/imgs_test_global.npy',imgs_test_global)\n",
    "np.save('./TFM/datasets/train_test/tags_test_global.npy',tags_test_global)\n",
    "np.save('./TFM/datasets/train_test/tags_test_globalbin.npy',tags_test_globalbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 9))\n",
    "\n",
    "plt.subplot(1,2, 1)\n",
    "plt.imshow(imgs_train_t1[18],cmap='gray')\n",
    "\n",
    "plt.subplot(1,2, 2)\n",
    "plt.imshow(tags_train_t1bin[18],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('TFM/x_train.npy', imgs_train)\n",
    "# np.save('TFM/x_test.npy', imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('TFM/y_train.npy', tags_train)\n",
    "# np.save('TFM/y_test.npy', tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
